services:
  vllm:
    image: vllm/vllm-openai:latest
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    environment:
      - HUGGING_FACE_HUB_TOKEN=${HF_TOKEN}
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface
    ports:
      - "8000:8000"
    ipc: host
    command: --model openai/gpt-oss-20b --dtype bfloat16 --gpu-memory-utilization 0.80

  whisper:
    image: sefboonen/carevoice-whisper:latest
    ports:
      - "9000:9000"
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - ORT_LOGGING_LEVEL=3
      - DEVICE_MODE=cuda
      - MODEL_NAME=large-v3
      - COMPUTE_FLOAT=int8_float16